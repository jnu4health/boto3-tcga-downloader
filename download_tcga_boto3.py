#!/usr/bin/env python3
import csv
import os
import argparse
import hashlib
import sys
import datetime
import time

try:
    import boto3
    from botocore.exceptions import (
        ClientError,
        NoCredentialsError,
        PartialCredentialsError,
    )
    from botocore.config import Config
    from botocore import UNSIGNED  # ç”¨äº --no-sign-request
except ImportError:
    print("é”™è¯¯ï¼šboto3 åŒ…æœªæ‰¾åˆ°ã€‚è¯·å…ˆå®‰è£…ï¼špip install boto3", file=sys.stderr)
    sys.exit(1)

# TCGA å¼€æ”¾æ•°æ®çš„ S3 å­˜å‚¨æ¡¶
S3_BUCKET_OPEN = "s3://tcga-2-open"  # è„šæœ¬ä¸­ä¼šç§»é™¤ 's3://' å‰ç¼€ç”¨äºboto3

# é»˜è®¤æ–‡ä»¶åå’Œç›®å½•
DEFAULT_OUTPUT_DIR_HELP = "/home/huozh/demo/code-project/A-DataSet/GDC"
DEFAULT_LOG_SUBDIR = "download_logs"  # å­˜æ”¾ä¸»æ—¥å¿—çš„å­ç›®å½•å
DEFAULT_DATASET_SUBDIR = "tcga_dataset"  # å­˜æ”¾ä¸‹è½½çš„TCGAæ•°æ®æ–‡ä»¶çš„å­ç›®å½•å
DEFAULT_LOG_FILE = "tcga_download_log.tsv"  # ä¸»æ—¥å¿—æ–‡ä»¶å


def calculate_md5(file_path, block_size=8192):
    """è®¡ç®—æœ¬åœ°æ–‡ä»¶çš„ MD5 æ ¡éªŒå’Œã€‚"""
    if not os.path.exists(file_path):
        return None, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
    md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            while True:
                data = f.read(block_size)
                if not data:
                    break
                md5.update(data)
        return md5.hexdigest(), None
    except IOError as e:
        return None, f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}"
    except Exception as e:
        return None, f"è®¡ç®—MD5æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"


def parse_manifest(manifest_file_path):
    """è§£æ GDC manifest æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ã€‚"""
    files_to_process = []
    col_options_id = ["id", "uuid", "file_id"]
    col_options_filename = ["filename", "file_name"]
    col_options_md5 = ["md5", "md5sum"]
    col_options_size = ["size", "file_size"]  # size åˆ—æ˜¯å¯é€‰çš„

    try:
        with open(manifest_file_path, "r", newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter="\t")

            actual_col_names = {}
            if not reader.fieldnames:
                print(
                    f"é”™è¯¯ï¼šManifest æ–‡ä»¶ '{manifest_file_path}' ä¸ºç©ºæˆ–æ— æ³•è¯»å–åˆ—åã€‚",
                    file=sys.stderr,
                )
                return None

            for expected_col_group, options in [
                ("id", col_options_id),
                ("filename", col_options_filename),
                ("md5", col_options_md5),
                ("size", col_options_size),
            ]:
                found = False
                for option in options:
                    if option in reader.fieldnames:
                        actual_col_names[expected_col_group] = option
                        found = True
                        break
                if not found and expected_col_group != "size":
                    print(
                        f"é”™è¯¯ï¼šManifest æ–‡ä»¶ '{manifest_file_path}' å¿…é¡»åŒ…å« '{expected_col_group}' (æˆ–å…¶å˜ä½“å¦‚ {options}) åˆ—ã€‚"
                        f"æ‰¾åˆ°çš„åˆ—: {reader.fieldnames}",
                        file=sys.stderr,
                    )
                    return None
                elif not found and expected_col_group == "size":
                    actual_col_names["size"] = None

            for row_number, row in enumerate(reader, 1):
                file_uuid = row.get(actual_col_names.get("id"))
                file_name = row.get(actual_col_names.get("filename"))
                md5_checksum = row.get(actual_col_names.get("md5"))
                file_size = (
                    row.get(actual_col_names.get("size"))
                    if actual_col_names.get("size")
                    else "N/A"
                )

                if not file_uuid or not file_name or not md5_checksum:
                    print(
                        f"è­¦å‘Šï¼šè·³è¿‡ Manifest æ–‡ä»¶çš„ç¬¬ {row_number} è¡Œï¼Œå› ä¸ºç¼ºå°‘ id, filename, æˆ– md5: {row}",
                        file=sys.stderr,
                    )
                    continue
                files_to_process.append(
                    {
                        "uuid": file_uuid,
                        "name": file_name,
                        "md5": md5_checksum.lower(),  # ç¡®ä¿MD5æ˜¯å°å†™ä»¥ä¾¿æ¯”è¾ƒ
                        "size": file_size,
                    }
                )
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šManifest æ–‡ä»¶æœªåœ¨è·¯å¾„ {manifest_file_path} æ‰¾åˆ°", file=sys.stderr)
        return None
    except Exception as e:
        print(
            f"é”™è¯¯ï¼šè§£æ Manifest æ–‡ä»¶ '{manifest_file_path}' å¤±è´¥: {e}",
            file=sys.stderr,
        )
        return None
    return files_to_process


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ GDC Manifest æ–‡ä»¶å’Œ AWS SDK (boto3) ç›´æ¥ä» TCGA S3 å­˜å‚¨æ¡¶ä¸‹è½½æ•°æ®ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "-m", "--manifest", required=True, help="GDC Manifest æ–‡ä»¶çš„è·¯å¾„ (TSV æ ¼å¼)ã€‚"
    )
    parser.add_argument(
        "-o",
        "--output-base-dir",
        required=True,
        help=f"æŒ‡å®šä¸€ä¸ªé¡¹ç›®åŸºç¡€è¾“å‡ºç›®å½•ã€‚æ—¥å¿—å°†å­˜æ”¾åœ¨æ­¤ç›®å½•ä¸‹çš„ '{DEFAULT_LOG_SUBDIR}/' å­ç›®å½•ä¸­ï¼ŒTCGA æ•°æ®å°†ä¸‹è½½åˆ°æ­¤ç›®å½•ä¸‹çš„ '{DEFAULT_DATASET_SUBDIR}/[UUID]/' å­ç›®å½•ä¸­ã€‚ä¾‹å¦‚ï¼š{DEFAULT_OUTPUT_DIR_HELP}",
    )
    parser.add_argument(
        "-b",
        "--s3-bucket",
        default=S3_BUCKET_OPEN,
        help="ä»ä¸­ä¸‹è½½çš„ S3 å­˜å‚¨æ¡¶ (ä¾‹å¦‚ 's3://bucket-name' æˆ– 'bucket-name')ã€‚",
    )
    parser.add_argument("--aws-profile", help="ç”¨äº S3 è®¿é—®çš„ AWS CLI profile åç§°ã€‚")
    parser.add_argument(
        "--no-sign-request",
        action="store_true",
        help="ä¸‹è½½æ—¶ä½¿ç”¨ AWS SDK çš„åŒ¿åè®¿é—®é€‰é¡¹ (ç›¸å½“äº awscli çš„ --no-sign-request)ã€‚"
        "å¦‚æœ --s3-bucket æ˜¯ tcga-2-open ä¸”æœªè®¾ç½® --aws-profileï¼Œåˆ™æ­¤é¡¹é»˜è®¤å¯ç”¨ã€‚",
    )
    parser.add_argument(
        "--skip-existing",
        action="store_true",
        help="å¦‚æœç›®æ ‡ä½ç½®å·²å­˜åœ¨æ•°æ®æ–‡ä»¶ä¸”å…¶ MD5 æ ¡éªŒå’ŒåŒ¹é…ï¼Œåˆ™è·³è¿‡ä¸‹è½½ã€‚",
    )
    parser.add_argument(
        "--log-file-name",
        default=DEFAULT_LOG_FILE,
        help="ä¸»æ—¥å¿—æ–‡ä»¶çš„åç§° (å­˜æ”¾äºæ—¥å¿—å­ç›®å½•ä¸­)ã€‚",
    )
    parser.add_argument(
        "--log-subdir",
        default=DEFAULT_LOG_SUBDIR,
        help="å­˜æ”¾ä¸»æ—¥å¿—æ–‡ä»¶çš„å­ç›®å½•åç§°ã€‚",
    )
    parser.add_argument(
        "--dataset-subdir",
        default=DEFAULT_DATASET_SUBDIR,
        help="å­˜æ”¾ä¸‹è½½çš„ TCGA æ•°æ®æ–‡ä»¶çš„å­ç›®å½•åç§°ã€‚",
    )
    parser.add_argument(
        "--retries", type=int, default=3, help="AWS S3 ä¸‹è½½å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚"
    )
    parser.add_argument(
        "--retry-delay", type=int, default=5, help="AWS S3 ä¸‹è½½é‡è¯•ä¹‹é—´çš„å»¶è¿Ÿç§’æ•°ã€‚"
    )

    args = parser.parse_args()

    # å¤„ç† S3 bucket åç§°ï¼Œç§»é™¤ 's3://' å‰ç¼€
    s3_bucket_name = args.s3_bucket.replace("s3://", "")

    use_no_sign_request_flag = args.no_sign_request
    if (
        args.s3_bucket.replace("s3://", "") == S3_BUCKET_OPEN.replace("s3://", "")
        and not args.aws_profile
    ):
        use_no_sign_request_flag = True
        print(
            "ä¿¡æ¯ï¼šç”±äºç›®æ ‡æ˜¯å…¬å¼€çš„ TCGA S3 å­˜å‚¨æ¡¶ä¸”æœªæŒ‡å®š AWS profileï¼Œå°†è‡ªåŠ¨å¯ç”¨ --no-sign-requestã€‚",
            file=sys.stdout,
        )
    if (
        args.s3_bucket.replace("s3://", "") != S3_BUCKET_OPEN.replace("s3://", "")
        and args.no_sign_request
    ):
        print(
            f"è­¦å‘Šï¼šä¸ºå­˜å‚¨æ¡¶ '{s3_bucket_name}' æŒ‡å®šäº† --no-sign-requestã€‚"
            "æ­¤é€‰é¡¹é€šå¸¸ç”¨äºå…¬å…±å­˜å‚¨æ¡¶ã€‚è®¿é—®å—æ§æ•°æ®å¯èƒ½ä¼šå¤±è´¥ã€‚",
            file=sys.stderr,
        )

    file_infos = parse_manifest(args.manifest)
    if not file_infos:
        sys.exit(1)

    project_base_dir = os.path.abspath(args.output_base_dir)
    log_actual_dir = os.path.join(project_base_dir, args.log_subdir)
    data_base_download_dir = os.path.join(project_base_dir, args.dataset_subdir)

    try:
        os.makedirs(log_actual_dir, exist_ok=True)
        os.makedirs(data_base_download_dir, exist_ok=True)
    except OSError as e:
        print(f"é”™è¯¯ï¼šæ— æ³•åˆ›å»ºåŸºç¡€è¾“å‡ºç›®å½•æˆ–å…¶å­ç›®å½•: {e}", file=sys.stderr)
        sys.exit(1)

    log_file_path = os.path.join(log_actual_dir, args.log_file_name)

    print(f"ä¿¡æ¯ï¼šåœ¨ Manifest æ–‡ä»¶ä¸­æ‰¾åˆ° {len(file_infos)} ä¸ªæ–‡ä»¶ã€‚")
    print(f"ä¿¡æ¯ï¼šæ•°æ®æ–‡ä»¶å°†ä¸‹è½½åˆ°: {data_base_download_dir}")
    print(f"ä¿¡æ¯ï¼šæ—¥å¿—æ–‡ä»¶å°†ä¿å­˜åœ¨: {log_file_path}")

    # åˆå§‹åŒ– boto3 S3 å®¢æˆ·ç«¯
    s3_client_config_args = {}
    if use_no_sign_request_flag:
        s3_client_config_args["config"] = Config(signature_version=UNSIGNED)

    session_args = {}
    if args.aws_profile:
        session_args["profile_name"] = args.aws_profile

    try:
        session = boto3.Session(**session_args)
        s3_client = session.client("s3", **s3_client_config_args)
        # å°è¯•åˆ—å‡ºå­˜å‚¨æ¡¶ä»¥éªŒè¯å‡­æ®å’Œå­˜å‚¨æ¡¶æ˜¯å¦å­˜åœ¨ï¼ˆå¯é€‰ï¼Œä½†æœ‰åŠ©äºæ—©æœŸå‘ç°é—®é¢˜ï¼‰
        # s3_client.list_objects_v2(Bucket=s3_bucket_name, MaxKeys=1)
    except (NoCredentialsError, PartialCredentialsError) as e:
        print(f"é”™è¯¯ï¼šAWSå‡­è¯é…ç½®ä¸æ­£ç¡®æˆ–ç¼ºå¤±: {e}", file=sys.stderr)
        if args.aws_profile:
            print(
                f"è¯·æ£€æŸ¥æ‚¨çš„AWS profile '{args.aws_profile}' æ˜¯å¦é…ç½®æ­£ç¡®ã€‚",
                file=sys.stderr,
            )
        else:
            print(
                "è¯·æ£€æŸ¥é»˜è®¤çš„AWSå‡­è¯ (ç¯å¢ƒå˜é‡æˆ– ~/.aws/credentials)ã€‚", file=sys.stderr
            )
        if not use_no_sign_request_flag:
            print(
                "å¦‚æœæ‚¨å¸Œæœ›åŒ¿åè®¿é—®å…¬å…±å­˜å‚¨æ¡¶ï¼Œè¯·å°è¯•ä½¿ç”¨ --no-sign-request é€‰é¡¹ã€‚",
                file=sys.stderr,
            )
        sys.exit(1)
    except ClientError as e:
        if e.response["Error"]["Code"] == "NoSuchBucket":
            print(
                f"é”™è¯¯ï¼šS3å­˜å‚¨æ¡¶ '{s3_bucket_name}' ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ã€‚", file=sys.stderr
            )
        else:
            print(f"é”™è¯¯ï¼šè¿æ¥åˆ°S3æ—¶å‘ç”Ÿé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:  # å…¶ä»– boto3 åˆå§‹åŒ–ç›¸å…³çš„å¼‚å¸¸
        print(f"é”™è¯¯ï¼šåˆå§‹åŒ–AWS S3å®¢æˆ·ç«¯å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

    # ç»Ÿè®¡ä¿¡æ¯
    summary_stats = {
        "total_manifest": len(file_infos),
        "processed": 0,
        "successful_md5_match": 0,
        "skipped_md5_match": 0,
        "failed_md5_mismatch": 0,
        "failed_aws_download": 0,
        "failed_md5_calc": 0,
        "failed_other": 0,
        "failed_files_details": [],  # å­˜æ”¾å¤±è´¥æ–‡ä»¶çš„ (uuid, filename, reason)
    }

    log_fieldnames = [
        "æ—¶é—´æˆ³",
        "çŠ¶æ€",
        "UUID",
        "æ–‡ä»¶å",
        "S3_URI",
        "æœ¬åœ°è·¯å¾„",
        "é¢„æœŸMD5",
        "å®é™…MD5",
        "æ–‡ä»¶å¤§å°(manifest)",
        "æ¶ˆæ¯",
    ]

    with open(log_file_path, "w", newline="", encoding="utf-8") as log_f:
        log_writer = csv.DictWriter(log_f, fieldnames=log_fieldnames, delimiter="\t")
        log_writer.writeheader()

        for i, file_info in enumerate(file_infos):
            summary_stats["processed"] += 1
            current_file_num = i + 1
            uuid = file_info["uuid"]
            file_name = file_info["name"]
            expected_md5 = file_info["md5"]
            file_size_manifest = file_info["size"]

            s3_key = f"{uuid}/{file_name}"
            s3_uri = f"s3://{s3_bucket_name}/{s3_key}"

            # æ¯ä¸ªæ–‡ä»¶å­˜æ”¾åœ¨å…¶UUIDå‘½åçš„å­ç›®å½•ä¸‹
            target_data_uuid_dir = os.path.join(data_base_download_dir, uuid)
            local_file_path = os.path.join(target_data_uuid_dir, file_name)

            log_entry = {
                "æ—¶é—´æˆ³": "",
                "çŠ¶æ€": "",
                "UUID": uuid,
                "æ–‡ä»¶å": file_name,
                "S3_URI": s3_uri,
                "æœ¬åœ°è·¯å¾„": local_file_path,
                "é¢„æœŸMD5": expected_md5,
                "å®é™…MD5": "N/A",
                "æ–‡ä»¶å¤§å°(manifest)": file_size_manifest,
                "æ¶ˆæ¯": "",
            }

            def write_log(status, actual_md5="N/A", message=""):
                log_entry["æ—¶é—´æˆ³"] = datetime.datetime.now(
                    datetime.timezone.utc
                ).isoformat()
                log_entry["çŠ¶æ€"] = status
                log_entry["å®é™…MD5"] = actual_md5 if actual_md5 else "N/A"
                log_entry["æ¶ˆæ¯"] = message
                log_writer.writerow(log_entry)
                log_f.flush()  # ç¡®ä¿ç«‹å³å†™å…¥

            print(
                f"\n>>> æ­£åœ¨å¤„ç†æ–‡ä»¶ {current_file_num}/{summary_stats['total_manifest']}: {file_name} (UUID: {uuid})"
            )

            try:
                os.makedirs(target_data_uuid_dir, exist_ok=True)
            except OSError as e:
                message = f"åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥: {e}"
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log("å¤±è´¥_å…¶ä»–", message=message)
                summary_stats["failed_other"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_å…¶ä»–",
                        "reason": message,
                    }
                )
                continue

            if args.skip_existing and os.path.exists(local_file_path):
                print(f"  ä¿¡æ¯: æ–‡ä»¶å·²å­˜åœ¨äº {local_file_path}ã€‚æ­£åœ¨è®¡ç®—æœ¬åœ° MD5...")
                local_md5, md5_error = calculate_md5(local_file_path)
                if md5_error:
                    message = f"è®¡ç®—æœ¬åœ°MD5å¤±è´¥: {md5_error}"
                    print(f"  é”™è¯¯: {message}", file=sys.stderr)
                    write_log(
                        "å¤±è´¥_MD5è®¡ç®—é”™è¯¯", actual_md5="è®¡ç®—å‡ºé”™", message=message
                    )
                    summary_stats["failed_md5_calc"] += 1
                    summary_stats["failed_files_details"].append(
                        {
                            "uuid": uuid,
                            "filename": file_name,
                            "status": "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                            "reason": message,
                        }
                    )
                    # å³ä½¿MD5è®¡ç®—å¤±è´¥ï¼Œå¦‚æœè®¾ç½®äº†skip-existingï¼Œæˆ‘ä»¬å¯èƒ½ä»é€‰æ‹©ä¸é‡æ–°ä¸‹è½½ï¼Œæˆ–è€…æ ‡è®°åç»§ç»­ä¸‹è½½
                    # è¿™é‡Œé€‰æ‹©ç»§ç»­å°è¯•ä¸‹è½½ï¼Œå› ä¸ºæ— æ³•ç¡®è®¤æ–‡ä»¶æ˜¯å¦æ­£ç¡®
                elif local_md5 == expected_md5:
                    message = "æ–‡ä»¶å·²å­˜åœ¨ä¸”MD5åŒ¹é…ã€‚"
                    print(f"  æˆåŠŸ: {message} ({expected_md5})")
                    write_log("å·²è·³è¿‡_MD5åŒ¹é…", actual_md5=local_md5, message=message)
                    summary_stats["skipped_md5_match"] += 1
                    continue  # è·³è¿‡ä¸‹è½½
                else:
                    print(
                        f"  è­¦å‘Š: æ–‡ä»¶å·²å­˜åœ¨ä½†MD5ä¸åŒ¹é… (é¢„æœŸ: {expected_md5}, æœ¬åœ°: {local_md5})ã€‚å°†é‡æ–°ä¸‹è½½ã€‚"
                    )
                    # ç»§ç»­æ‰§è¡Œä¸‹è½½æµç¨‹

            # ä¸‹è½½æ–‡ä»¶
            print(f"  ä¿¡æ¯: æ­£åœ¨ä» {s3_uri} ä¸‹è½½åˆ° {local_file_path}...")
            download_success = False
            for attempt in range(args.retries + 1):
                try:
                    s3_client.download_file(s3_bucket_name, s3_key, local_file_path)
                    download_success = True
                    print(f"  ä¿¡æ¯: ä¸‹è½½å®Œæˆã€‚")
                    break  # ä¸‹è½½æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                except ClientError as e:
                    message = (
                        f"AWS S3ä¸‹è½½é”™è¯¯ (å°è¯• {attempt + 1}/{args.retries + 1}): {e}"
                    )
                    print(f"  é”™è¯¯: {message}", file=sys.stderr)
                    if attempt < args.retries:
                        print(f"  ä¿¡æ¯: {args.retry_delay}ç§’åé‡è¯•...")
                        time.sleep(args.retry_delay)
                    else:
                        write_log("å¤±è´¥_AWSä¸‹è½½", message=f"AWS S3ä¸‹è½½æœ€ç»ˆå¤±è´¥: {e}")
                        summary_stats["failed_aws_download"] += 1
                        summary_stats["failed_files_details"].append(
                            {
                                "uuid": uuid,
                                "filename": file_name,
                                "status": "å¤±è´¥_AWSä¸‹è½½",
                                "reason": str(e),
                            }
                        )
                except Exception as e:  # å…¶ä»–å¯èƒ½çš„ä¸‹è½½æ—¶å¼‚å¸¸
                    message = f"ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯ (å°è¯• {attempt + 1}): {e}"
                    print(f"  é”™è¯¯: {message}", file=sys.stderr)
                    # å¯¹äºæœªçŸ¥é”™è¯¯ï¼Œé€šå¸¸ä¸å»ºè®®ç›²ç›®é‡è¯•
                    write_log("å¤±è´¥_å…¶ä»–", message=message)
                    summary_stats["failed_other"] += 1
                    summary_stats["failed_files_details"].append(
                        {
                            "uuid": uuid,
                            "filename": file_name,
                            "status": "å¤±è´¥_å…¶ä»–",
                            "reason": str(e),
                        }
                    )
                    break  # è·³å‡ºé‡è¯•

            if not download_success:
                continue  # ä¸‹è½½å¤±è´¥ï¼Œå¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶

            # MD5 æ ¡éªŒä¸‹è½½åçš„æ–‡ä»¶
            print(f"  ä¿¡æ¯: æ­£åœ¨æ ¡éªŒä¸‹è½½æ–‡ä»¶çš„ MD5...")
            actual_md5, md5_error = calculate_md5(local_file_path)
            if md5_error:
                message = f"è®¡ç®—ä¸‹è½½åæ–‡ä»¶MD5å¤±è´¥: {md5_error}"
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log("å¤±è´¥_MD5è®¡ç®—é”™è¯¯", actual_md5="è®¡ç®—å‡ºé”™", message=message)
                summary_stats["failed_md5_calc"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                        "reason": message,
                    }
                )
            elif actual_md5 == expected_md5:
                message = "ä¸‹è½½æˆåŠŸä¸”MD5åŒ¹é…ã€‚"
                print(f"  æˆåŠŸ: {message} ({actual_md5})")
                write_log("æˆåŠŸ_MD5åŒ¹é…", actual_md5=actual_md5, message=message)
                summary_stats["successful_md5_match"] += 1
            else:
                message = (
                    f"æ–‡ä»¶å·²ä¸‹è½½ä½†MD5ä¸åŒ¹é… (é¢„æœŸ: {expected_md5}, å®é™…: {actual_md5})"
                )
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log("å¤±è´¥_MD5ä¸åŒ¹é…", actual_md5=actual_md5, message=message)
                summary_stats["failed_md5_mismatch"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_MD5ä¸åŒ¹é…",
                        "reason": message,
                    }
                )

    # --- ä»»åŠ¡å®Œæˆåçš„æ‘˜è¦ä¿¡æ¯ ---
    print("\n\n==================================================")
    print("          ä¸‹è½½ä»»åŠ¡å®Œæˆæ‘˜è¦")
    print("==================================================")
    print(f" Manifest æ–‡ä»¶ä¸­å£°æ˜çš„æ€»æ–‡ä»¶æ•°: {summary_stats['total_manifest']}")
    print(f" æœ¬æ¬¡è¿è¡Œå°è¯•å¤„ç†çš„æ–‡ä»¶æ•°: {summary_stats['processed']}")
    print("--------------------------------------------------")
    print(f" âœ… æˆåŠŸä¸‹è½½å¹¶é€šè¿‡æ ¡éªŒçš„æ–‡ä»¶æ•°: {summary_stats['successful_md5_match']}")
    print(f" â­ï¸ å› å·²å­˜åœ¨ä¸”MD5åŒ¹é…è€Œè·³è¿‡çš„æ–‡ä»¶æ•°: {summary_stats['skipped_md5_match']}")
    print("--------------------------------------------------")
    total_failed = (
        summary_stats["failed_md5_mismatch"]
        + summary_stats["failed_aws_download"]
        + summary_stats["failed_md5_calc"]
        + summary_stats["failed_other"]
    )
    print(f" âŒ ä¸‹è½½å¤±è´¥æˆ–æ ¡éªŒæœªé€šè¿‡çš„æ–‡ä»¶æ€»æ•°: {total_failed}")
    if total_failed > 0:
        print(f"    - MD5 ä¸åŒ¹é…æ•°é‡: {summary_stats['failed_md5_mismatch']}")
        print(f"    - AWS ä¸‹è½½å¤±è´¥æ•°é‡: {summary_stats['failed_aws_download']}")
        print(f"    - æœ¬åœ°/ä¸‹è½½åMD5è®¡ç®—é”™è¯¯æ•°é‡: {summary_stats['failed_md5_calc']}")
        print(f"    - å…¶ä»–é”™è¯¯æ•°é‡: {summary_stats['failed_other']}")
    print("--------------------------------------------------")

    if summary_stats["failed_files_details"]:
        print("\nä»¥ä¸‹æ–‡ä»¶ä¸‹è½½å¤±è´¥æˆ–æ ¡éªŒæœªé€šè¿‡ (çŠ¶æ€ | UUID | æ–‡ä»¶å | åŸå› ):")
        # æ ¹æ®çŠ¶æ€æ’åºï¼Œä½¿ç›¸åŒç±»å‹çš„é”™è¯¯åœ¨ä¸€èµ·
        sorted_failures = sorted(
            summary_stats["failed_files_details"], key=lambda x: x["status"]
        )
        for fail_info in sorted_failures:
            print(
                f"  - {fail_info['status']:<20} | {fail_info['uuid']:<37} | {fail_info['filename']:<50} | {fail_info['reason']}"
            )
        print("\nè¯·æ£€æŸ¥ä¸»æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(f"  {log_file_path}")
    elif summary_stats["processed"] > 0 and total_failed == 0:
        print("ğŸ‰ æ‰€æœ‰å·²å¤„ç†çš„æ–‡ä»¶å‡å·²æˆåŠŸä¸‹è½½/è·³è¿‡å¹¶é€šè¿‡æ ¡éªŒã€‚")
    elif summary_stats["processed"] == 0 and summary_stats["total_manifest"] > 0:
        print(
            "ğŸ¤” æœ¬æ¬¡è¿è¡Œæ²¡æœ‰å¤„ç†ä»»ä½•æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼Œå¯èƒ½æ‰€æœ‰æ–‡ä»¶éƒ½è¢«manifestè§£æé˜¶æ®µè·³è¿‡äº†ï¼‰ã€‚"
        )
    elif summary_stats["total_manifest"] == 0:
        print("â„¹ï¸ Manifest æ–‡ä»¶ä¸ºç©ºæˆ–æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆæ¡ç›®ã€‚")

    print("==================================================")
    print(f"è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹: {log_file_path}")


if __name__ == "__main__":
    main()
