#!/usr/bin/env python3
import csv
import os
import argparse
import hashlib
import sys
import datetime
import time

try:
    import boto3
    from botocore.exceptions import (
        ClientError,
        NoCredentialsError,
        PartialCredentialsError,
    )
    from botocore.config import Config
    from botocore import UNSIGNED  # ç”¨äº --no-sign-request
except ImportError:
    print("é”™è¯¯ï¼šboto3 åŒ…æœªæ‰¾åˆ°ã€‚è¯·å…ˆå®‰è£…ï¼špip install boto3", file=sys.stderr)
    sys.exit(1)

# TCGA å¼€æ”¾æ•°æ®çš„ S3 å­˜å‚¨æ¡¶
S3_BUCKET_OPEN = "s3://tcga-2-open"  # è„šæœ¬ä¸­ä¼šç§»é™¤ 's3://' å‰ç¼€ç”¨äºboto3

# é»˜è®¤æ–‡ä»¶åå’Œç›®å½•
DEFAULT_OUTPUT_DIR_HELP = "/home/user/project/GDC_data"  # ç¤ºä¾‹è·¯å¾„ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
DEFAULT_LOG_SUBDIR = "download_logs"  # å­˜æ”¾ä¸»æ—¥å¿—çš„å­ç›®å½•å
DEFAULT_DATASET_SUBDIR = "tcga_dataset"  # å­˜æ”¾ä¸‹è½½çš„TCGAæ•°æ®æ–‡ä»¶çš„å­ç›®å½•å
DEFAULT_LOG_FILE = "tcga_download_log.tsv"  # ä¸»æ—¥å¿—æ–‡ä»¶å


def calculate_md5(file_path, block_size=8192):
    """è®¡ç®—æœ¬åœ°æ–‡ä»¶çš„ MD5 æ ¡éªŒå’Œã€‚"""
    if not os.path.exists(file_path):
        return None, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
    md5_hash = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            while True:
                data = f.read(block_size)
                if not data:
                    break
                md5_hash.update(data)
        return md5_hash.hexdigest(), None
    except IOError as e:
        return None, f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}"
    except Exception as e:
        return None, f"è®¡ç®—MD5æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"


def parse_manifest(manifest_file_path):
    """è§£æ GDC manifest æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ã€‚"""
    files_to_process = []
    col_options_id = ["id", "uuid", "file_id"]
    col_options_filename = ["filename", "file_name"]
    col_options_md5 = ["md5", "md5sum"]
    col_options_size = ["size", "file_size"]  # size åˆ—æ˜¯å¯é€‰çš„

    try:
        with open(manifest_file_path, "r", newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter="\t")

            actual_col_names = {}
            if not reader.fieldnames:
                print(
                    f"é”™è¯¯ï¼šManifest æ–‡ä»¶ '{manifest_file_path}' ä¸ºç©ºæˆ–æ— æ³•è¯»å–åˆ—åã€‚",
                    file=sys.stderr,
                )
                return None

            for expected_col_group, options in [
                ("id", col_options_id),
                ("filename", col_options_filename),
                ("md5", col_options_md5),
                ("size", col_options_size),
            ]:
                found = False
                for option in options:
                    if option in reader.fieldnames:
                        actual_col_names[expected_col_group] = option
                        found = True
                        break
                if (
                    not found and expected_col_group != "size"
                ):  # id, filename, md5 æ˜¯å¿…é¡»çš„
                    print(
                        f"é”™è¯¯ï¼šManifest æ–‡ä»¶ '{manifest_file_path}' å¿…é¡»åŒ…å« '{expected_col_group}' (æˆ–å…¶å˜ä½“å¦‚ {options}) åˆ—ã€‚"
                        f"æ‰¾åˆ°çš„åˆ—: {reader.fieldnames}",
                        file=sys.stderr,
                    )
                    return None
                elif not found and expected_col_group == "size":
                    actual_col_names["size"] = None  # size åˆ—æ˜¯å¯é€‰çš„

            for row_number, row in enumerate(reader, 1):
                file_uuid = row.get(actual_col_names.get("id"))
                file_name = row.get(actual_col_names.get("filename"))
                md5_checksum = row.get(actual_col_names.get("md5"))
                file_size = (
                    row.get(actual_col_names.get("size"))
                    if actual_col_names.get("size")
                    else "N/A"
                )

                if not file_uuid or not file_name or not md5_checksum:
                    print(
                        f"è­¦å‘Šï¼šè·³è¿‡ Manifest æ–‡ä»¶çš„ç¬¬ {row_number} è¡Œï¼Œå› ä¸ºç¼ºå°‘ id, filename, æˆ– md5: {row}",
                        file=sys.stderr,
                    )
                    continue
                files_to_process.append(
                    {
                        "uuid": file_uuid,
                        "name": file_name,
                        "md5": md5_checksum.lower(),  # ç¡®ä¿MD5æ˜¯å°å†™ä»¥ä¾¿æ¯”è¾ƒ
                        "size": file_size,
                    }
                )
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šManifest æ–‡ä»¶æœªåœ¨è·¯å¾„ {manifest_file_path} æ‰¾åˆ°", file=sys.stderr)
        return None
    except Exception as e:
        print(
            f"é”™è¯¯ï¼šè§£æ Manifest æ–‡ä»¶ '{manifest_file_path}' å¤±è´¥: {e}",
            file=sys.stderr,
        )
        return None
    return files_to_process


def check_s3_object_existence_for_download(s3_client, bucket_name, s3_key):
    """
    æ£€æŸ¥ S3 å¯¹è±¡æ˜¯å¦å­˜åœ¨ä»¥åŠæ˜¯å¦å¯è®¿é—®ã€‚
    è¿”å›: (exists: bool, status_code_enum: int, message: str)
    status_code_enum: 0 = å­˜åœ¨, 1 = æœªæ‰¾åˆ°(404), 2 = ç¦æ­¢è®¿é—®(403), 3 = å…¶ä»–AWSå®¢æˆ·ç«¯é”™è¯¯, 4 = æœªçŸ¥é”™è¯¯
    """
    try:
        s3_client.head_object(Bucket=bucket_name, Key=s3_key)
        return True, 0, "æ–‡ä»¶å­˜åœ¨"
    except ClientError as e:
        error_code = e.response.get("Error", {}).get("Code")
        http_status_code = e.response.get("ResponseMetadata", {}).get("HTTPStatusCode")
        error_message_detail = str(e)  # å®Œæ•´çš„é”™è¯¯ä¿¡æ¯

        if error_code == "404" or error_code == "NoSuchKey" or http_status_code == 404:
            return (
                False,
                1,
                f"æ–‡ä»¶æœªæ‰¾åˆ° (404 Not Found) - S3 Code: {error_code}, HTTP Status: {http_status_code}. Details: {error_message_detail}",
            )
        elif error_code == "403" or http_status_code == 403:
            return (
                False,
                2,
                f"è®¿é—®è¢«æ‹’ç» (403 Forbidden) - S3 Code: {error_code}, HTTP Status: {http_status_code}. Details: {error_message_detail}",
            )
        else:
            # å…¶ä»–ç±»å‹çš„ ClientError
            return (
                False,
                3,
                f"AWS API å®¢æˆ·ç«¯é”™è¯¯: S3 Code: {error_code}, HTTP Status: {http_status_code}. Details: {error_message_detail}",
            )
    except Exception as e:
        # å…¶ä»–é ClientError çš„å¼‚å¸¸
        return False, 4, f"æ£€æŸ¥S3å¯¹è±¡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ GDC Manifest æ–‡ä»¶å’Œ AWS SDK (boto3) ç›´æ¥ä» TCGA S3 å­˜å‚¨æ¡¶ä¸‹è½½æ•°æ®ã€‚å¢åŠ S3æ–‡ä»¶å­˜åœ¨æ€§é¢„æ£€æŸ¥åŠŸèƒ½ï¼Œå¹¶å¯æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿›è¡Œè¿‡æ»¤ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "-m", "--manifest", required=True, help="GDC Manifest æ–‡ä»¶çš„è·¯å¾„ (TSV æ ¼å¼)ã€‚"
    )
    parser.add_argument(
        "-o",
        "--output-base-dir",
        required=True,
        help=f"æŒ‡å®šä¸€ä¸ªé¡¹ç›®åŸºç¡€è¾“å‡ºç›®å½•ã€‚æ—¥å¿—å°†å­˜æ”¾åœ¨æ­¤ç›®å½•ä¸‹çš„ '{DEFAULT_LOG_SUBDIR}/' å­ç›®å½•ä¸­ï¼ŒTCGA æ•°æ®å°†ä¸‹è½½åˆ°æ­¤ç›®å½•ä¸‹çš„ '{DEFAULT_DATASET_SUBDIR}/[UUID]/' å­ç›®å½•ä¸­ã€‚ä¾‹å¦‚ï¼š{DEFAULT_OUTPUT_DIR_HELP}",
    )
    parser.add_argument(
        "-e",
        "--allowed-extensions",
        type=str,
        default=None,
        help="å…è®¸ä¸‹è½½çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼Œä»¥é€—å·åˆ†éš” (ä¾‹å¦‚ 'svs,bam,txt')ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ã€‚æ‰©å±•åä¸åŒºåˆ†å¤§å°å†™ï¼Œä¸éœ€è¦åŒ…å«ç‚¹(.)ã€‚",
    )
    parser.add_argument(
        "-b",
        "--s3-bucket",
        default=S3_BUCKET_OPEN,
        help="ä»ä¸­ä¸‹è½½çš„ S3 å­˜å‚¨æ¡¶ (ä¾‹å¦‚ 's3://bucket-name' æˆ– 'bucket-name')ã€‚",
    )
    parser.add_argument("--aws-profile", help="ç”¨äº S3 è®¿é—®çš„ AWS CLI profile åç§°ã€‚")
    parser.add_argument(
        "--no-sign-request",
        action="store_true",
        help="ä¸‹è½½æ—¶ä½¿ç”¨ AWS SDK çš„åŒ¿åè®¿é—®é€‰é¡¹ (ç›¸å½“äº awscli çš„ --no-sign-request)ã€‚"
        "å¦‚æœ --s3-bucket æ˜¯ tcga-2-open ä¸”æœªè®¾ç½® --aws-profileï¼Œåˆ™æ­¤é¡¹é»˜è®¤å¯ç”¨ã€‚",
    )
    parser.add_argument(
        "--skip-existing",
        action="store_true",
        help="å¦‚æœç›®æ ‡ä½ç½®å·²å­˜åœ¨æ•°æ®æ–‡ä»¶ä¸”å…¶ MD5 æ ¡éªŒå’ŒåŒ¹é…ï¼Œåˆ™è·³è¿‡ä¸‹è½½ã€‚",
    )
    parser.add_argument(
        "--log-file-name",
        default=DEFAULT_LOG_FILE,
        help="ä¸»æ—¥å¿—æ–‡ä»¶çš„åç§° (å­˜æ”¾äºæ—¥å¿—å­ç›®å½•ä¸­)ã€‚",
    )
    parser.add_argument(
        "--log-subdir",
        default=DEFAULT_LOG_SUBDIR,
        help="å­˜æ”¾ä¸»æ—¥å¿—æ–‡ä»¶çš„å­ç›®å½•åç§°ã€‚",
    )
    parser.add_argument(
        "--dataset-subdir",
        default=DEFAULT_DATASET_SUBDIR,
        help="å­˜æ”¾ä¸‹è½½çš„ TCGA æ•°æ®æ–‡ä»¶çš„å­ç›®å½•åç§°ã€‚",
    )
    parser.add_argument(
        "--retries",
        type=int,
        default=1,  # åŸä¸º3ï¼Œæ ¹æ®ç”¨æˆ·æä¾›çš„è„šæœ¬æ˜¯1
        help="AWS S3 ä¸‹è½½å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚",
    )
    parser.add_argument(
        "--retry-delay",
        type=int,
        default=2,  # åŸä¸º5ï¼Œæ ¹æ®ç”¨æˆ·æä¾›çš„è„šæœ¬æ˜¯2
        help="AWS S3 ä¸‹è½½é‡è¯•ä¹‹é—´çš„å»¶è¿Ÿç§’æ•°ã€‚",
    )

    args = parser.parse_args()

    # å¤„ç†å…è®¸çš„æ‰©å±•å
    allowed_extensions_set = set()
    if args.allowed_extensions:
        allowed_extensions_set = {
            ext.strip().lower().lstrip(".")
            for ext in args.allowed_extensions.split(",")
            if ext.strip()
        }
        print(f"ä¿¡æ¯ï¼šå°†åªä¸‹è½½ä»¥ä¸‹æ‰©å±•åçš„æ–‡ä»¶: {', '.join(allowed_extensions_set)}")

    s3_bucket_name = args.s3_bucket.replace("s3://", "")

    use_no_sign_request_flag = args.no_sign_request
    if (
        s3_bucket_name == S3_BUCKET_OPEN.replace("s3://", "")  # æ¯”è¾ƒæ—¶ä¸å¸¦ s3://
        and not args.aws_profile
    ):
        use_no_sign_request_flag = True
        print(
            "ä¿¡æ¯ï¼šç”±äºç›®æ ‡æ˜¯å…¬å¼€çš„ TCGA S3 å­˜å‚¨æ¡¶ä¸”æœªæŒ‡å®š AWS profileï¼Œå°†è‡ªåŠ¨å¯ç”¨ --no-sign-requestã€‚",
            file=sys.stdout,
        )
    if s3_bucket_name != S3_BUCKET_OPEN.replace("s3://", "") and args.no_sign_request:
        print(
            f"è­¦å‘Šï¼šä¸ºå­˜å‚¨æ¡¶ '{s3_bucket_name}' æŒ‡å®šäº† --no-sign-requestã€‚"
            "æ­¤é€‰é¡¹é€šå¸¸ç”¨äºå…¬å…±å­˜å‚¨æ¡¶ã€‚è®¿é—®å—æ§æ•°æ®å¯èƒ½ä¼šå¤±è´¥ã€‚",
            file=sys.stderr,
        )

    initial_file_infos = parse_manifest(args.manifest)
    if not initial_file_infos:
        sys.exit(1)

    # æ ¹æ®æ‰©å±•åè¿‡æ»¤æ–‡ä»¶
    file_infos_to_download = []
    skipped_due_to_extension = []

    if allowed_extensions_set:
        for file_info_item in initial_file_infos:  # é¿å…ä¸å¤–å±‚å˜é‡é‡å
            file_ext = os.path.splitext(file_info_item["name"])[1].lstrip(".").lower()
            if file_ext in allowed_extensions_set:
                file_infos_to_download.append(file_info_item)
            else:
                skipped_due_to_extension.append(file_info_item)
        print(
            f"ä¿¡æ¯ï¼šæ ¹æ®æ‰©å±•åè¿‡æ»¤åï¼Œå°†å°è¯•ä¸‹è½½ {len(file_infos_to_download)} ä¸ªæ–‡ä»¶ã€‚"
        )
        if skipped_due_to_extension:
            print(
                f"ä¿¡æ¯ï¼š{len(skipped_due_to_extension)} ä¸ªæ–‡ä»¶å› æ‰©å±•åä¸åŒ¹é…è€Œè¢«è·³è¿‡ã€‚"
            )
    else:
        file_infos_to_download = initial_file_infos
        print(
            f"ä¿¡æ¯ï¼šæœªæŒ‡å®šæ‰©å±•åè¿‡æ»¤å™¨ï¼Œå°†å°è¯•ä¸‹è½½ Manifest ä¸­çš„æ‰€æœ‰ {len(initial_file_infos)} ä¸ªæ–‡ä»¶ã€‚"
        )

    project_base_dir = os.path.abspath(args.output_base_dir)
    log_actual_dir = os.path.join(project_base_dir, args.log_subdir)
    data_base_download_dir = os.path.join(project_base_dir, args.dataset_subdir)

    try:
        os.makedirs(log_actual_dir, exist_ok=True)
        os.makedirs(data_base_download_dir, exist_ok=True)
    except OSError as e:
        print(f"é”™è¯¯ï¼šæ— æ³•åˆ›å»ºåŸºç¡€è¾“å‡ºç›®å½•æˆ–å…¶å­ç›®å½•: {e}", file=sys.stderr)
        sys.exit(1)

    log_file_path = os.path.join(log_actual_dir, args.log_file_name)

    print(f"ä¿¡æ¯ï¼šæ•°æ®æ–‡ä»¶å°†ä¸‹è½½åˆ°: {data_base_download_dir}")
    print(f"ä¿¡æ¯ï¼šæ—¥å¿—æ–‡ä»¶å°†ä¿å­˜åœ¨: {log_file_path}")

    s3_client_config_args = {}
    if use_no_sign_request_flag:
        s3_client_config_args["config"] = Config(signature_version=UNSIGNED)

    session_args = {}
    if args.aws_profile:
        session_args["profile_name"] = args.aws_profile

    try:
        session = boto3.Session(**session_args)
        s3_client = session.client("s3", **s3_client_config_args)
        # æµ‹è¯•S3è¿æ¥ (å¯é€‰ï¼Œä½†æœ‰åŠ©äºæ—©æœŸå‘ç°é—®é¢˜)
        s3_client.head_bucket(Bucket=s3_bucket_name)
        print(f"ä¿¡æ¯ï¼šæˆåŠŸè¿æ¥åˆ°S3å­˜å‚¨æ¡¶ '{s3_bucket_name}'ã€‚")
    except (NoCredentialsError, PartialCredentialsError) as e:
        print(f"é”™è¯¯ï¼šAWSå‡­è¯é…ç½®ä¸æ­£ç¡®æˆ–ç¼ºå¤±: {e}", file=sys.stderr)
        if args.aws_profile:
            print(
                f"è¯·æ£€æŸ¥æ‚¨çš„AWS profile '{args.aws_profile}' æ˜¯å¦é…ç½®æ­£ç¡®ã€‚",
                file=sys.stderr,
            )
        else:
            print(
                "è¯·æ£€æŸ¥é»˜è®¤çš„AWSå‡­è¯ (ç¯å¢ƒå˜é‡æˆ– ~/.aws/credentials)ã€‚", file=sys.stderr
            )
        if not use_no_sign_request_flag:  # åªæœ‰åœ¨æ²¡æœ‰ä½¿ç”¨ no_sign_request æ—¶æ‰æç¤ºè¿™ä¸ª
            print(
                "å¦‚æœæ‚¨å¸Œæœ›åŒ¿åè®¿é—®å…¬å…±å­˜å‚¨æ¡¶ï¼Œè¯·å°è¯•ä½¿ç”¨ --no-sign-request é€‰é¡¹ã€‚",
                file=sys.stderr,
            )
        sys.exit(1)
    except ClientError as e:
        if e.response["Error"]["Code"] == "NoSuchBucket":
            print(
                f"é”™è¯¯ï¼šS3å­˜å‚¨æ¡¶ '{s3_bucket_name}' ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ã€‚", file=sys.stderr
            )
        elif (
            e.response["Error"]["Code"] == "Forbidden" and not use_no_sign_request_flag
        ):
            print(
                f"é”™è¯¯ï¼šè®¿é—®S3å­˜å‚¨æ¡¶ '{s3_bucket_name}' è¢«æ‹’ç» (Forbidden)ã€‚è¯·æ£€æŸ¥å‡­è¯å’Œå­˜å‚¨æ¡¶ç­–ç•¥ã€‚",
                file=sys.stderr,
            )
        else:
            print(f"é”™è¯¯ï¼šè¿æ¥åˆ°S3æˆ–æµ‹è¯•å­˜å‚¨æ¡¶æ—¶å‘ç”Ÿé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:  # å…¶ä»–åˆå§‹åŒ–é”™è¯¯
        print(f"é”™è¯¯ï¼šåˆå§‹åŒ–AWS S3å®¢æˆ·ç«¯å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

    summary_stats = {
        "total_manifest": len(initial_file_infos),
        "total_filtered_for_download": len(file_infos_to_download),
        "processed_from_filtered": 0,
        "successful_md5_match": 0,
        "skipped_md5_match": 0,
        "skipped_extension_mismatch": len(skipped_due_to_extension),
        "skipped_s3_not_found": 0,  # æ–°å¢ï¼šå› S3æ–‡ä»¶æœªæ‰¾åˆ°è€Œè·³è¿‡
        "skipped_s3_forbidden": 0,  # æ–°å¢ï¼šå› S3è®¿é—®è¢«æ‹’ç»è€Œè·³è¿‡
        "skipped_s3_other_error": 0,  # æ–°å¢ï¼šå› S3æ£€æŸ¥æ—¶å…¶ä»–é”™è¯¯è€Œè·³è¿‡
        "failed_md5_mismatch": 0,
        "failed_aws_download": 0,
        "failed_md5_calc": 0,
        "failed_other": 0,
        "failed_files_details": [],  # ç”¨äºè®°å½•æ‰€æœ‰å¤±è´¥æˆ–æ˜ç¡®è·³è¿‡ï¼ˆS3æ£€æŸ¥å¤±è´¥ï¼‰çš„æ¡ç›®
    }

    log_fieldnames = [
        "æ—¶é—´æˆ³",
        "çŠ¶æ€",
        "UUID",
        "æ–‡ä»¶å",
        "S3_URI",
        "æœ¬åœ°è·¯å¾„",
        "é¢„æœŸMD5",
        "å®é™…MD5",
        "æ–‡ä»¶å¤§å°(manifest)",
        "æ¶ˆæ¯",
    ]

    with open(log_file_path, "w", newline="", encoding="utf-8") as log_f:
        log_writer = csv.DictWriter(log_f, fieldnames=log_fieldnames, delimiter="\t")
        log_writer.writeheader()

        def write_log_entry(
            status,
            uuid,
            file_name,
            s3_uri="N/A",
            local_path="N/A",
            expected_md5="N/A",
            actual_md5="N/A",
            size="N/A",
            message="",
        ):
            entry = {
                "æ—¶é—´æˆ³": datetime.datetime.now(datetime.timezone.utc).isoformat(),
                "çŠ¶æ€": status,
                "UUID": uuid,
                "æ–‡ä»¶å": file_name,
                "S3_URI": s3_uri,
                "æœ¬åœ°è·¯å¾„": local_path,
                "é¢„æœŸMD5": expected_md5,
                "å®é™…MD5": actual_md5 if actual_md5 else "N/A",
                "æ–‡ä»¶å¤§å°(manifest)": size,
                "æ¶ˆæ¯": message,
            }
            log_writer.writerow(entry)
            log_f.flush()

        # è®°å½•å› æ‰©å±•åä¸åŒ¹é…è€Œè·³è¿‡çš„æ–‡ä»¶
        for file_info_item in skipped_due_to_extension:
            s3_key_skipped = f"{file_info_item['uuid']}/{file_info_item['name']}"
            s3_uri_skipped = f"s3://{s3_bucket_name}/{s3_key_skipped}"
            write_log_entry(
                status="è·³è¿‡_æ‰©å±•åä¸åŒ¹é…",
                uuid=file_info_item["uuid"],
                file_name=file_info_item["name"],
                s3_uri=s3_uri_skipped,
                expected_md5=file_info_item["md5"],
                size=file_info_item["size"],
                message=f"æ–‡ä»¶æ‰©å±•å '{os.path.splitext(file_info_item['name'])[1].lstrip('.').lower()}' ä¸åœ¨å…è®¸çš„åˆ—è¡¨ä¸­ ({', '.join(allowed_extensions_set) if allowed_extensions_set else 'æ— é™åˆ¶'})ã€‚",
            )

        for i, file_info in enumerate(file_infos_to_download):
            summary_stats["processed_from_filtered"] += 1
            current_file_num = i + 1
            uuid = file_info["uuid"]
            file_name = file_info["name"]
            expected_md5 = file_info["md5"]
            file_size_manifest = file_info["size"]

            s3_key = f"{uuid}/{file_name}"
            s3_uri = f"s3://{s3_bucket_name}/{s3_key}"

            target_data_uuid_dir = os.path.join(data_base_download_dir, uuid)
            local_file_path = os.path.join(target_data_uuid_dir, file_name)

            print(
                f"\n>>> æ­£åœ¨å¤„ç†æ–‡ä»¶ {current_file_num}/{summary_stats['total_filtered_for_download']}: {file_name} (UUID: {uuid})"
            )

            # --- æ–°å¢ï¼šS3æ–‡ä»¶å­˜åœ¨æ€§é¢„æ£€æŸ¥ ---
            print(f"  ä¿¡æ¯: æ­£åœ¨å¯¹S3å¯¹è±¡è¿›è¡Œé¢„æ£€æŸ¥: {s3_uri}...")
            s3_exists, s3_check_status_code, s3_check_message = (
                check_s3_object_existence_for_download(
                    s3_client, s3_bucket_name, s3_key
                )
            )

            if not s3_exists:
                log_status = "è·³è¿‡_S3æ£€æŸ¥é”™è¯¯"  # é»˜è®¤
                reason_prefix = "S3å¯¹è±¡é¢„æ£€æŸ¥å¤±è´¥"
                if s3_check_status_code == 1:  # 404 Not Found
                    summary_stats["skipped_s3_not_found"] += 1
                    log_status = "è·³è¿‡_S3æ–‡ä»¶æœªæ‰¾åˆ°"
                    reason_prefix = "S3å¯¹è±¡æœªæ‰¾åˆ°"
                elif s3_check_status_code == 2:  # 403 Forbidden
                    summary_stats["skipped_s3_forbidden"] += 1
                    log_status = "è·³è¿‡_S3ç¦æ­¢è®¿é—®"
                    reason_prefix = "S3å¯¹è±¡è®¿é—®è¢«ç¦æ­¢"
                else:  # å…¶ä»–S3æ£€æŸ¥é”™è¯¯ (status_code 3 or 4)
                    summary_stats["skipped_s3_other_error"] += 1

                full_message = f"{reason_prefix}: {s3_check_message}"
                print(f"  è­¦å‘Š: {full_message} å°†è·³è¿‡ä¸‹è½½æ­¤æ–‡ä»¶ã€‚", file=sys.stderr)
                write_log_entry(
                    status=log_status,
                    uuid=uuid,
                    file_name=file_name,
                    s3_uri=s3_uri,
                    local_path=local_file_path,  # è®°å½•è®¡åˆ’çš„æœ¬åœ°è·¯å¾„
                    expected_md5=expected_md5,
                    size=file_size_manifest,
                    message=full_message,
                )
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": log_status,
                        "reason": full_message,
                    }
                )
                continue  # è·³è¿‡æ­¤æ–‡ä»¶çš„åç»­ä¸‹è½½å’ŒMD5æ ¡éªŒ
            else:
                print(f"  ä¿¡æ¯: S3å¯¹è±¡é¢„æ£€æŸ¥é€šè¿‡: {s3_check_message}")
            # --- S3æ–‡ä»¶å­˜åœ¨æ€§é¢„æ£€æŸ¥ç»“æŸ ---

            try:
                os.makedirs(target_data_uuid_dir, exist_ok=True)
            except OSError as e:
                message = f"åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥: {e}"
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log_entry(
                    "å¤±è´¥_å…¶ä»–",
                    uuid,
                    file_name,
                    s3_uri,
                    local_file_path,
                    expected_md5,
                    "N/A",
                    file_size_manifest,
                    message,
                )
                summary_stats["failed_other"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_å…¶ä»–",
                        "reason": message,
                    }
                )
                continue

            if args.skip_existing and os.path.exists(local_file_path):
                print(f"  ä¿¡æ¯: æ–‡ä»¶å·²å­˜åœ¨äº {local_file_path}ã€‚æ­£åœ¨è®¡ç®—æœ¬åœ° MD5...")
                local_md5, md5_error = calculate_md5(local_file_path)
                if md5_error:
                    message = f"è®¡ç®—æœ¬åœ°MD5å¤±è´¥: {md5_error}"
                    print(f"  é”™è¯¯: {message}", file=sys.stderr)
                    write_log_entry(
                        "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                        uuid,
                        file_name,
                        s3_uri,
                        local_file_path,
                        expected_md5,
                        "è®¡ç®—å‡ºé”™",
                        file_size_manifest,
                        message,
                    )
                    summary_stats["failed_md5_calc"] += 1
                    summary_stats["failed_files_details"].append(
                        {
                            "uuid": uuid,
                            "filename": file_name,
                            "status": "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                            "reason": message,
                        }
                    )
                elif local_md5 == expected_md5:
                    message = "æ–‡ä»¶å·²å­˜åœ¨ä¸”MD5åŒ¹é…ã€‚"
                    print(f"  æˆåŠŸ: {message} ({expected_md5})")
                    write_log_entry(
                        "å·²è·³è¿‡_MD5åŒ¹é…",
                        uuid,
                        file_name,
                        s3_uri,
                        local_file_path,
                        expected_md5,
                        local_md5,
                        file_size_manifest,
                        message,
                    )
                    summary_stats["skipped_md5_match"] += 1
                    continue
                else:
                    print(
                        f"  è­¦å‘Š: æ–‡ä»¶å·²å­˜åœ¨ä½†MD5ä¸åŒ¹é… (é¢„æœŸ: {expected_md5}, æœ¬åœ°: {local_md5})ã€‚å°†é‡æ–°ä¸‹è½½ã€‚"
                    )

            print(f"  ä¿¡æ¯: æ­£åœ¨ä» {s3_uri} ä¸‹è½½åˆ° {local_file_path}...")
            download_success = False
            last_exception_message = "æœªçŸ¥ä¸‹è½½é”™è¯¯"
            for attempt in range(args.retries + 1):  # +1 ä½¿å…¶åŒ…æ‹¬åˆå§‹å°è¯•
                try:
                    s3_client.download_file(s3_bucket_name, s3_key, local_file_path)
                    download_success = True
                    print(f"  ä¿¡æ¯: ä¸‹è½½å®Œæˆã€‚")
                    break
                except ClientError as e:  # AWSç›¸å…³çš„ä¸‹è½½é”™è¯¯
                    last_exception_message = (
                        f"AWS S3ä¸‹è½½é”™è¯¯ (å°è¯• {attempt + 1}/{args.retries + 1}): {e}"
                    )
                    print(f"  é”™è¯¯: {last_exception_message}", file=sys.stderr)
                    if attempt < args.retries:
                        print(f"  ä¿¡æ¯: {args.retry_delay}ç§’åé‡è¯•...")
                        time.sleep(args.retry_delay)
                    # else: # æœ€ç»ˆå¤±è´¥çš„è®°å½•ç§»åˆ°å¾ªç¯å¤–
                except Exception as e:  # å…¶ä»–éAWSçš„ä¸‹è½½é”™è¯¯ (ä¾‹å¦‚ç£ç›˜ç©ºé—´ä¸è¶³ç­‰)
                    last_exception_message = (
                        f"ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯ (å°è¯• {attempt + 1}): {e}"
                    )
                    print(f"  é”™è¯¯: {last_exception_message}", file=sys.stderr)
                    # å¯¹äºéClientErrorï¼Œé€šå¸¸ä¸è¿›è¡Œé‡è¯•ï¼Œç›´æ¥è®°å½•å¤±è´¥å¹¶è·³å‡º
                    write_log_entry(
                        "å¤±è´¥_å…¶ä»–",
                        uuid,
                        file_name,
                        s3_uri,
                        local_file_path,
                        expected_md5,
                        "N/A",
                        file_size_manifest,
                        last_exception_message,
                    )
                    summary_stats["failed_other"] += 1
                    summary_stats["failed_files_details"].append(
                        {
                            "uuid": uuid,
                            "filename": file_name,
                            "status": "å¤±è´¥_å…¶ä»–",
                            "reason": last_exception_message,  # ä½¿ç”¨æ›´æ–°åçš„æ¶ˆæ¯
                        }
                    )
                    download_success = False  # ç¡®ä¿æ ‡è®°ä¸ºå¤±è´¥
                    break  # è·³å‡ºé‡è¯•å¾ªç¯

            if not download_success:
                # å¦‚æœæ˜¯å› ä¸ºClientErrorä¸”é‡è¯•æ¬¡æ•°è€—å°½è€Œå¤±è´¥
                if (
                    "AWS S3ä¸‹è½½é”™è¯¯" in last_exception_message
                ):  # æ£€æŸ¥æ˜¯å¦æ˜¯ClientErrorå¯¼è‡´çš„å¤±è´¥
                    write_log_entry(
                        "å¤±è´¥_AWSä¸‹è½½",
                        uuid,
                        file_name,
                        s3_uri,
                        local_file_path,
                        expected_md5,
                        "N/A",
                        file_size_manifest,
                        f"AWS S3ä¸‹è½½æœ€ç»ˆå¤±è´¥: {last_exception_message}",  # ä½¿ç”¨æ›´æ–°åçš„æ¶ˆæ¯
                    )
                    summary_stats["failed_aws_download"] += 1
                    summary_stats["failed_files_details"].append(
                        {
                            "uuid": uuid,
                            "filename": file_name,
                            "status": "å¤±è´¥_AWSä¸‹è½½",
                            "reason": last_exception_message,  # ä½¿ç”¨æ›´æ–°åçš„æ¶ˆæ¯
                        }
                    )
                # å¦‚æœæ˜¯å› ä¸ºå…¶ä»–é”™è¯¯ï¼ˆå·²åœ¨å¾ªç¯å†…è®°å½•ï¼‰ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤è®°å½•
                continue  # è¿›è¡Œä¸‹ä¸€ä¸ªæ–‡ä»¶çš„å¤„ç†

            print(f"  ä¿¡æ¯: æ­£åœ¨æ ¡éªŒä¸‹è½½æ–‡ä»¶çš„ MD5...")
            actual_md5_downloaded, md5_error_downloaded = calculate_md5(local_file_path)
            if md5_error_downloaded:
                message = f"è®¡ç®—ä¸‹è½½åæ–‡ä»¶MD5å¤±è´¥: {md5_error_downloaded}"
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log_entry(
                    "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                    uuid,
                    file_name,
                    s3_uri,
                    local_file_path,
                    expected_md5,
                    "è®¡ç®—å‡ºé”™",
                    file_size_manifest,
                    message,
                )
                summary_stats["failed_md5_calc"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                        "reason": message,
                    }
                )
            elif actual_md5_downloaded == expected_md5:
                message = "ä¸‹è½½æˆåŠŸä¸”MD5åŒ¹é…ã€‚"
                print(f"  æˆåŠŸ: {message} ({actual_md5_downloaded})")
                write_log_entry(
                    "æˆåŠŸ_MD5åŒ¹é…",
                    uuid,
                    file_name,
                    s3_uri,
                    local_file_path,
                    expected_md5,
                    actual_md5_downloaded,
                    file_size_manifest,
                    message,
                )
                summary_stats["successful_md5_match"] += 1
            else:
                message = f"æ–‡ä»¶å·²ä¸‹è½½ä½†MD5ä¸åŒ¹é… (é¢„æœŸ: {expected_md5}, å®é™…: {actual_md5_downloaded})"
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log_entry(
                    "å¤±è´¥_MD5ä¸åŒ¹é…",
                    uuid,
                    file_name,
                    s3_uri,
                    local_file_path,
                    expected_md5,
                    actual_md5_downloaded,
                    file_size_manifest,
                    message,
                )
                summary_stats["failed_md5_mismatch"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_MD5ä¸åŒ¹é…",
                        "reason": message,
                    }
                )

    print("\n\n==================================================")
    print("          ä¸‹è½½ä»»åŠ¡å®Œæˆæ‘˜è¦")
    print("==================================================")
    print(f" Manifest æ–‡ä»¶ä¸­å£°æ˜çš„æ€»æ–‡ä»¶æ•°: {summary_stats['total_manifest']}")
    print(
        f" æ ¹æ®æ‰©å±•åè¿‡æ»¤åè®¡åˆ’ä¸‹è½½çš„æ–‡ä»¶æ•°: {summary_stats['total_filtered_for_download']}"
    )
    print(
        f" â­ï¸ å› æ‰©å±•åä¸åŒ¹é…è€Œè·³è¿‡çš„æ–‡ä»¶æ•°: {summary_stats['skipped_extension_mismatch']}"
    )
    print(
        f" æœ¬æ¬¡è¿è¡Œå®é™…å°è¯•å¤„ç†çš„æ–‡ä»¶æ•° (æ¥è‡ªè¿‡æ»¤ååˆ—è¡¨): {summary_stats['processed_from_filtered']}"
    )
    print("--------------------------------------------------")
    print(f" S3é¢„æ£€æŸ¥é˜¶æ®µè·³è¿‡çš„æ–‡ä»¶:")
    print(
        f"    - â­ï¸ å› S3æ–‡ä»¶æœªæ‰¾åˆ° (404) è€Œè·³è¿‡: {summary_stats['skipped_s3_not_found']}"
    )
    print(
        f"    - â­ï¸ å› S3è®¿é—®è¢«æ‹’ç» (403) è€Œè·³è¿‡: {summary_stats['skipped_s3_forbidden']}"
    )
    print(
        f"    - â­ï¸ å› S3æ£€æŸ¥æ—¶å…¶ä»–é”™è¯¯è€Œè·³è¿‡: {summary_stats['skipped_s3_other_error']}"
    )
    print("--------------------------------------------------")
    print(f" âœ… æˆåŠŸä¸‹è½½å¹¶é€šè¿‡æ ¡éªŒçš„æ–‡ä»¶æ•°: {summary_stats['successful_md5_match']}")
    print(
        f" â­ï¸ å› æœ¬åœ°å·²å­˜åœ¨ä¸”MD5åŒ¹é…è€Œè·³è¿‡çš„æ–‡ä»¶æ•°: {summary_stats['skipped_md5_match']}"
    )
    print("--------------------------------------------------")

    total_download_and_md5_failures = (
        summary_stats["failed_md5_mismatch"]
        + summary_stats["failed_aws_download"]
        + summary_stats["failed_md5_calc"]
        + summary_stats["failed_other"]
    )
    print(f" âŒ ä¸‹è½½æˆ–MD5æ ¡éªŒé˜¶æ®µå¤±è´¥çš„æ–‡ä»¶æ€»æ•°: {total_download_and_md5_failures}")
    if total_download_and_md5_failures > 0:
        print(f"    - MD5 ä¸åŒ¹é…æ•°é‡: {summary_stats['failed_md5_mismatch']}")
        print(f"    - AWS ä¸‹è½½å¤±è´¥æ•°é‡: {summary_stats['failed_aws_download']}")
        print(f"    - æœ¬åœ°/ä¸‹è½½åMD5è®¡ç®—é”™è¯¯æ•°é‡: {summary_stats['failed_md5_calc']}")
        print(f"    - å…¶ä»–é”™è¯¯æ•°é‡ (å¦‚ç›®å½•åˆ›å»ºå¤±è´¥): {summary_stats['failed_other']}")
    print("--------------------------------------------------")

    if summary_stats["failed_files_details"]:
        print("\nä»¥ä¸‹æ–‡ä»¶æœªèƒ½æˆåŠŸå¤„ç†çš„è¯¦æƒ… (çŠ¶æ€ | UUID | æ–‡ä»¶å | åŸå› ):")
        # æ’åºï¼Œå¯ä»¥æŒ‰çŠ¶æ€ï¼Œç„¶åæŒ‰æ–‡ä»¶å
        sorted_failures_and_skips = sorted(
            summary_stats["failed_files_details"],
            key=lambda x: (x["status"], x["filename"]),
        )
        for item_info in sorted_failures_and_skips:  # æ›´é€šç”¨çš„å˜é‡å
            print(
                f"  - {item_info['status']:<25} | {item_info['uuid']:<37} | {item_info['filename']:<50} | {item_info['reason']}"
            )
        print("\nè¯·æ£€æŸ¥ä¸»æ—¥å¿—æ–‡ä»¶è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œä¸Šä¸‹æ–‡:")
        print(f"  {log_file_path}")

    # æ ¹æ®æ•´ä½“ç»“æœç»™å‡ºæœ€ç»ˆçŠ¶æ€ä¿¡æ¯
    total_processed_successfully_or_skipped_appropriately = (
        summary_stats["successful_md5_match"]
        + summary_stats["skipped_md5_match"]
        + summary_stats["skipped_extension_mismatch"]
        + summary_stats["skipped_s3_not_found"]
        + summary_stats["skipped_s3_forbidden"]
        + summary_stats["skipped_s3_other_error"]
    )

    if (
        summary_stats["processed_from_filtered"] > 0
        and total_download_and_md5_failures == 0
        and (
            summary_stats["skipped_s3_not_found"]
            + summary_stats["skipped_s3_forbidden"]
            + summary_stats["skipped_s3_other_error"]
            == 0
        )
    ):
        # ä»…å½“æ²¡æœ‰S3é¢„æ£€è·³è¿‡ï¼Œå¹¶ä¸”æ²¡æœ‰ä¸‹è½½/MD5å¤±è´¥æ—¶ï¼Œæ‰ç®—å®Œç¾æˆåŠŸ
        if (
            summary_stats["successful_md5_match"] + summary_stats["skipped_md5_match"]
            == summary_stats["processed_from_filtered"]
        ):
            print(
                "\nğŸ‰ æ‰€æœ‰è®¡åˆ’å¤„ç†çš„æ–‡ä»¶å‡å·²æˆåŠŸä¸‹è½½/è·³è¿‡ï¼ˆæœ¬åœ°å·²å­˜åœ¨ä¸”åŒ¹é…ï¼‰å¹¶é€šè¿‡æ ¡éªŒã€‚"
            )

    elif summary_stats["total_manifest"] == 0:
        print("\nâ„¹ï¸ Manifest æ–‡ä»¶ä¸ºç©ºæˆ–æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆæ¡ç›®ã€‚")
    elif (
        summary_stats["total_filtered_for_download"] == 0
        and summary_stats["total_manifest"] > 0
    ):
        print("\nâ„¹ï¸ æ ¹æ®æ‰©å±•åè¿‡æ»¤åï¼Œæ²¡æœ‰æ–‡ä»¶ç¬¦åˆä¸‹è½½æ¡ä»¶ã€‚")
    # å¯ä»¥æ·»åŠ æ›´å¤šåŸºäºä¸åŒç»„åˆæƒ…å†µçš„æ€»ç»“æ€§è¾“å‡º

    print("==================================================")
    print(f"è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹: {log_file_path}")


if __name__ == "__main__":
    main()
