#!/usr/bin/env python3
import csv
import os
import argparse
import hashlib
import sys
import datetime
import time

try:
    import boto3
    from botocore.exceptions import (
        ClientError,
        NoCredentialsError,
        PartialCredentialsError,
    )
    from botocore.config import Config
    from botocore import UNSIGNED  # ç”¨äº --no-sign-request
except ImportError:
    print("é”™è¯¯ï¼šboto3 åŒ…æœªæ‰¾åˆ°ã€‚è¯·å…ˆå®‰è£…ï¼špip install boto3", file=sys.stderr)
    sys.exit(1)

# TCGA å¼€æ”¾æ•°æ®çš„ S3 å­˜å‚¨æ¡¶
S3_BUCKET_OPEN = "s3://tcga-2-open"  # è„šæœ¬ä¸­ä¼šç§»é™¤ 's3://' å‰ç¼€ç”¨äºboto3

# é»˜è®¤æ–‡ä»¶åå’Œç›®å½•
DEFAULT_OUTPUT_DIR_HELP = "/home/user/project/GDC_data"  # ç¤ºä¾‹è·¯å¾„ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
DEFAULT_LOG_SUBDIR = "download_logs"  # å­˜æ”¾ä¸»æ—¥å¿—çš„å­ç›®å½•å
DEFAULT_DATASET_SUBDIR = "tcga_dataset"  # å­˜æ”¾ä¸‹è½½çš„TCGAæ•°æ®æ–‡ä»¶çš„å­ç›®å½•å
DEFAULT_LOG_FILE = "tcga_download_log.tsv"  # ä¸»æ—¥å¿—æ–‡ä»¶å


def calculate_md5(file_path, block_size=8192):
    """è®¡ç®—æœ¬åœ°æ–‡ä»¶çš„ MD5 æ ¡éªŒå’Œã€‚"""
    if not os.path.exists(file_path):
        return None, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
    md5_hash = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            while True:
                data = f.read(block_size)
                if not data:
                    break
                md5_hash.update(data)
        return md5_hash.hexdigest(), None
    except IOError as e:
        return None, f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}"
    except Exception as e:
        return None, f"è®¡ç®—MD5æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"


def parse_manifest(manifest_file_path):
    """è§£æ GDC manifest æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨ã€‚"""
    files_to_process = []
    col_options_id = ["id", "uuid", "file_id"]
    col_options_filename = ["filename", "file_name"]
    col_options_md5 = ["md5", "md5sum"]
    col_options_size = ["size", "file_size"]  # size åˆ—æ˜¯å¯é€‰çš„

    try:
        with open(manifest_file_path, "r", newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter="\t")

            actual_col_names = {}
            if not reader.fieldnames:
                print(
                    f"é”™è¯¯ï¼šManifest æ–‡ä»¶ '{manifest_file_path}' ä¸ºç©ºæˆ–æ— æ³•è¯»å–åˆ—åã€‚",
                    file=sys.stderr,
                )
                return None

            for expected_col_group, options in [
                ("id", col_options_id),
                ("filename", col_options_filename),
                ("md5", col_options_md5),
                ("size", col_options_size),
            ]:
                found = False
                for option in options:
                    if option in reader.fieldnames:
                        actual_col_names[expected_col_group] = option
                        found = True
                        break
                if not found and expected_col_group != "size":
                    print(
                        f"é”™è¯¯ï¼šManifest æ–‡ä»¶ '{manifest_file_path}' å¿…é¡»åŒ…å« '{expected_col_group}' (æˆ–å…¶å˜ä½“å¦‚ {options}) åˆ—ã€‚"
                        f"æ‰¾åˆ°çš„åˆ—: {reader.fieldnames}",
                        file=sys.stderr,
                    )
                    return None
                elif not found and expected_col_group == "size":
                    actual_col_names["size"] = (
                        None  # size åˆ—æ˜¯å¯é€‰çš„ï¼Œæ‰€ä»¥è¿™é‡Œå…è®¸ None
                    )

            for row_number, row in enumerate(reader, 1):
                file_uuid = row.get(actual_col_names.get("id"))
                file_name = row.get(actual_col_names.get("filename"))
                md5_checksum = row.get(actual_col_names.get("md5"))
                file_size = (
                    row.get(actual_col_names.get("size"))
                    if actual_col_names.get("size")
                    else "N/A"
                )

                if not file_uuid or not file_name or not md5_checksum:
                    print(
                        f"è­¦å‘Šï¼šè·³è¿‡ Manifest æ–‡ä»¶çš„ç¬¬ {row_number} è¡Œï¼Œå› ä¸ºç¼ºå°‘ id, filename, æˆ– md5: {row}",
                        file=sys.stderr,
                    )
                    continue
                files_to_process.append(
                    {
                        "uuid": file_uuid,
                        "name": file_name,
                        "md5": md5_checksum.lower(),  # ç¡®ä¿MD5æ˜¯å°å†™ä»¥ä¾¿æ¯”è¾ƒ
                        "size": file_size,
                    }
                )
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šManifest æ–‡ä»¶æœªåœ¨è·¯å¾„ {manifest_file_path} æ‰¾åˆ°", file=sys.stderr)
        return None
    except Exception as e:
        print(
            f"é”™è¯¯ï¼šè§£æ Manifest æ–‡ä»¶ '{manifest_file_path}' å¤±è´¥: {e}",
            file=sys.stderr,
        )
        return None
    return files_to_process


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ GDC Manifest æ–‡ä»¶å’Œ AWS SDK (boto3) ç›´æ¥ä» TCGA S3 å­˜å‚¨æ¡¶ä¸‹è½½æ•°æ®ã€‚å¯ä»¥æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿›è¡Œè¿‡æ»¤ã€‚",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "-m", "--manifest", required=True, help="GDC Manifest æ–‡ä»¶çš„è·¯å¾„ (TSV æ ¼å¼)ã€‚"
    )
    parser.add_argument(
        "-o",
        "--output-base-dir",
        required=True,
        help=f"æŒ‡å®šä¸€ä¸ªé¡¹ç›®åŸºç¡€è¾“å‡ºç›®å½•ã€‚æ—¥å¿—å°†å­˜æ”¾åœ¨æ­¤ç›®å½•ä¸‹çš„ '{DEFAULT_LOG_SUBDIR}/' å­ç›®å½•ä¸­ï¼ŒTCGA æ•°æ®å°†ä¸‹è½½åˆ°æ­¤ç›®å½•ä¸‹çš„ '{DEFAULT_DATASET_SUBDIR}/[UUID]/' å­ç›®å½•ä¸­ã€‚ä¾‹å¦‚ï¼š{DEFAULT_OUTPUT_DIR_HELP}",
    )
    parser.add_argument(
        "-e",
        "--allowed-extensions",
        type=str,
        default=None,
        help="å…è®¸ä¸‹è½½çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼Œä»¥é€—å·åˆ†éš” (ä¾‹å¦‚ 'svs,bam,txt')ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ã€‚æ‰©å±•åä¸åŒºåˆ†å¤§å°å†™ï¼Œä¸éœ€è¦åŒ…å«ç‚¹(.)ã€‚",
    )
    parser.add_argument(
        "-b",
        "--s3-bucket",
        default=S3_BUCKET_OPEN,
        help="ä»ä¸­ä¸‹è½½çš„ S3 å­˜å‚¨æ¡¶ (ä¾‹å¦‚ 's3://bucket-name' æˆ– 'bucket-name')ã€‚",
    )
    parser.add_argument("--aws-profile", help="ç”¨äº S3 è®¿é—®çš„ AWS CLI profile åç§°ã€‚")
    parser.add_argument(
        "--no-sign-request",
        action="store_true",
        help="ä¸‹è½½æ—¶ä½¿ç”¨ AWS SDK çš„åŒ¿åè®¿é—®é€‰é¡¹ (ç›¸å½“äº awscli çš„ --no-sign-request)ã€‚"
        "å¦‚æœ --s3-bucket æ˜¯ tcga-2-open ä¸”æœªè®¾ç½® --aws-profileï¼Œåˆ™æ­¤é¡¹é»˜è®¤å¯ç”¨ã€‚",
    )
    parser.add_argument(
        "--skip-existing",
        action="store_true",
        help="å¦‚æœç›®æ ‡ä½ç½®å·²å­˜åœ¨æ•°æ®æ–‡ä»¶ä¸”å…¶ MD5 æ ¡éªŒå’ŒåŒ¹é…ï¼Œåˆ™è·³è¿‡ä¸‹è½½ã€‚",
    )
    parser.add_argument(
        "--log-file-name",
        default=DEFAULT_LOG_FILE,
        help="ä¸»æ—¥å¿—æ–‡ä»¶çš„åç§° (å­˜æ”¾äºæ—¥å¿—å­ç›®å½•ä¸­)ã€‚",
    )
    parser.add_argument(
        "--log-subdir",
        default=DEFAULT_LOG_SUBDIR,
        help="å­˜æ”¾ä¸»æ—¥å¿—æ–‡ä»¶çš„å­ç›®å½•åç§°ã€‚",
    )
    parser.add_argument(
        "--dataset-subdir",
        default=DEFAULT_DATASET_SUBDIR,
        help="å­˜æ”¾ä¸‹è½½çš„ TCGA æ•°æ®æ–‡ä»¶çš„å­ç›®å½•åç§°ã€‚",
    )
    parser.add_argument(
        "--retries",
        type=int,
        default=1,
        help="AWS S3 ä¸‹è½½å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚",  # ä¿®æ”¹é»˜è®¤å€¼
    )
    parser.add_argument(
        "--retry-delay",
        type=int,
        default=2,
        help="AWS S3 ä¸‹è½½é‡è¯•ä¹‹é—´çš„å»¶è¿Ÿç§’æ•°ã€‚",  # ä¿®æ”¹é»˜è®¤å€¼
    )

    args = parser.parse_args()

    # å¤„ç†å…è®¸çš„æ‰©å±•å
    allowed_extensions_set = set()
    if args.allowed_extensions:
        allowed_extensions_set = {
            ext.strip().lower().lstrip(".")
            for ext in args.allowed_extensions.split(",")
            if ext.strip()
        }
        print(f"ä¿¡æ¯ï¼šå°†åªä¸‹è½½ä»¥ä¸‹æ‰©å±•åçš„æ–‡ä»¶: {', '.join(allowed_extensions_set)}")

    s3_bucket_name = args.s3_bucket.replace("s3://", "")

    use_no_sign_request_flag = args.no_sign_request
    if (
        args.s3_bucket.replace("s3://", "") == S3_BUCKET_OPEN.replace("s3://", "")
        and not args.aws_profile
    ):
        use_no_sign_request_flag = True
        print(
            "ä¿¡æ¯ï¼šç”±äºç›®æ ‡æ˜¯å…¬å¼€çš„ TCGA S3 å­˜å‚¨æ¡¶ä¸”æœªæŒ‡å®š AWS profileï¼Œå°†è‡ªåŠ¨å¯ç”¨ --no-sign-requestã€‚",
            file=sys.stdout,
        )
    if (
        args.s3_bucket.replace("s3://", "") != S3_BUCKET_OPEN.replace("s3://", "")
        and args.no_sign_request
    ):
        print(
            f"è­¦å‘Šï¼šä¸ºå­˜å‚¨æ¡¶ '{s3_bucket_name}' æŒ‡å®šäº† --no-sign-requestã€‚"
            "æ­¤é€‰é¡¹é€šå¸¸ç”¨äºå…¬å…±å­˜å‚¨æ¡¶ã€‚è®¿é—®å—æ§æ•°æ®å¯èƒ½ä¼šå¤±è´¥ã€‚",
            file=sys.stderr,
        )

    initial_file_infos = parse_manifest(args.manifest)
    if not initial_file_infos:
        sys.exit(1)

    # æ ¹æ®æ‰©å±•åè¿‡æ»¤æ–‡ä»¶
    file_infos_to_download = []
    skipped_due_to_extension = []

    if allowed_extensions_set:
        for file_info in initial_file_infos:
            file_ext = os.path.splitext(file_info["name"])[1].lstrip(".").lower()
            if file_ext in allowed_extensions_set:
                file_infos_to_download.append(file_info)
            else:
                skipped_due_to_extension.append(file_info)
        print(
            f"ä¿¡æ¯ï¼šæ ¹æ®æ‰©å±•åè¿‡æ»¤åï¼Œå°†å°è¯•ä¸‹è½½ {len(file_infos_to_download)} ä¸ªæ–‡ä»¶ã€‚"
        )
        if skipped_due_to_extension:
            print(
                f"ä¿¡æ¯ï¼š{len(skipped_due_to_extension)} ä¸ªæ–‡ä»¶å› æ‰©å±•åä¸åŒ¹é…è€Œè¢«è·³è¿‡ã€‚"
            )
    else:
        file_infos_to_download = initial_file_infos
        print(
            f"ä¿¡æ¯ï¼šæœªæŒ‡å®šæ‰©å±•åè¿‡æ»¤å™¨ï¼Œå°†å°è¯•ä¸‹è½½ Manifest ä¸­çš„æ‰€æœ‰ {len(initial_file_infos)} ä¸ªæ–‡ä»¶ã€‚"
        )

    project_base_dir = os.path.abspath(args.output_base_dir)
    log_actual_dir = os.path.join(project_base_dir, args.log_subdir)
    data_base_download_dir = os.path.join(project_base_dir, args.dataset_subdir)

    try:
        os.makedirs(log_actual_dir, exist_ok=True)
        os.makedirs(data_base_download_dir, exist_ok=True)
    except OSError as e:
        print(f"é”™è¯¯ï¼šæ— æ³•åˆ›å»ºåŸºç¡€è¾“å‡ºç›®å½•æˆ–å…¶å­ç›®å½•: {e}", file=sys.stderr)
        sys.exit(1)

    log_file_path = os.path.join(log_actual_dir, args.log_file_name)

    print(f"ä¿¡æ¯ï¼šæ•°æ®æ–‡ä»¶å°†ä¸‹è½½åˆ°: {data_base_download_dir}")
    print(f"ä¿¡æ¯ï¼šæ—¥å¿—æ–‡ä»¶å°†ä¿å­˜åœ¨: {log_file_path}")

    s3_client_config_args = {}
    if use_no_sign_request_flag:
        s3_client_config_args["config"] = Config(signature_version=UNSIGNED)

    session_args = {}
    if args.aws_profile:
        session_args["profile_name"] = args.aws_profile

    try:
        session = boto3.Session(**session_args)
        s3_client = session.client("s3", **s3_client_config_args)
    except (NoCredentialsError, PartialCredentialsError) as e:
        print(f"é”™è¯¯ï¼šAWSå‡­è¯é…ç½®ä¸æ­£ç¡®æˆ–ç¼ºå¤±: {e}", file=sys.stderr)
        if args.aws_profile:
            print(
                f"è¯·æ£€æŸ¥æ‚¨çš„AWS profile '{args.aws_profile}' æ˜¯å¦é…ç½®æ­£ç¡®ã€‚",
                file=sys.stderr,
            )
        else:
            print(
                "è¯·æ£€æŸ¥é»˜è®¤çš„AWSå‡­è¯ (ç¯å¢ƒå˜é‡æˆ– ~/.aws/credentials)ã€‚", file=sys.stderr
            )
        if not use_no_sign_request_flag:
            print(
                "å¦‚æœæ‚¨å¸Œæœ›åŒ¿åè®¿é—®å…¬å…±å­˜å‚¨æ¡¶ï¼Œè¯·å°è¯•ä½¿ç”¨ --no-sign-request é€‰é¡¹ã€‚",
                file=sys.stderr,
            )
        sys.exit(1)
    except ClientError as e:
        if e.response["Error"]["Code"] == "NoSuchBucket":
            print(
                f"é”™è¯¯ï¼šS3å­˜å‚¨æ¡¶ '{s3_bucket_name}' ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ã€‚", file=sys.stderr
            )
        else:
            print(f"é”™è¯¯ï¼šè¿æ¥åˆ°S3æ—¶å‘ç”Ÿé”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"é”™è¯¯ï¼šåˆå§‹åŒ–AWS S3å®¢æˆ·ç«¯å¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)

    summary_stats = {
        "total_manifest": len(initial_file_infos),
        "total_filtered_for_download": len(file_infos_to_download),
        "processed_from_filtered": 0,
        "successful_md5_match": 0,
        "skipped_md5_match": 0,
        "skipped_extension_mismatch": len(skipped_due_to_extension),  # æ–°å¢ç»Ÿè®¡
        "failed_md5_mismatch": 0,
        "failed_aws_download": 0,
        "failed_md5_calc": 0,
        "failed_other": 0,
        "failed_files_details": [],
    }

    log_fieldnames = [
        "æ—¶é—´æˆ³",
        "çŠ¶æ€",
        "UUID",
        "æ–‡ä»¶å",
        "S3_URI",
        "æœ¬åœ°è·¯å¾„",
        "é¢„æœŸMD5",
        "å®é™…MD5",
        "æ–‡ä»¶å¤§å°(manifest)",
        "æ¶ˆæ¯",
    ]

    with open(log_file_path, "w", newline="", encoding="utf-8") as log_f:
        log_writer = csv.DictWriter(log_f, fieldnames=log_fieldnames, delimiter="\t")
        log_writer.writeheader()

        def write_log_entry(
            status,
            uuid,
            file_name,
            s3_uri="N/A",
            local_path="N/A",
            expected_md5="N/A",
            actual_md5="N/A",
            size="N/A",
            message="",
        ):
            entry = {
                "æ—¶é—´æˆ³": datetime.datetime.now(datetime.timezone.utc).isoformat(),
                "çŠ¶æ€": status,
                "UUID": uuid,
                "æ–‡ä»¶å": file_name,
                "S3_URI": s3_uri,
                "æœ¬åœ°è·¯å¾„": local_path,
                "é¢„æœŸMD5": expected_md5,
                "å®é™…MD5": actual_md5 if actual_md5 else "N/A",
                "æ–‡ä»¶å¤§å°(manifest)": size,
                "æ¶ˆæ¯": message,
            }
            log_writer.writerow(entry)
            log_f.flush()

        # è®°å½•å› æ‰©å±•åä¸åŒ¹é…è€Œè·³è¿‡çš„æ–‡ä»¶
        for file_info in skipped_due_to_extension:
            s3_key_skipped = f"{file_info['uuid']}/{file_info['name']}"
            s3_uri_skipped = f"s3://{s3_bucket_name}/{s3_key_skipped}"
            write_log_entry(
                status="è·³è¿‡_æ‰©å±•åä¸åŒ¹é…",
                uuid=file_info["uuid"],
                file_name=file_info["name"],
                s3_uri=s3_uri_skipped,
                expected_md5=file_info["md5"],
                size=file_info["size"],
                message=f"æ–‡ä»¶æ‰©å±•å '{os.path.splitext(file_info['name'])[1].lstrip('.').lower()}' ä¸åœ¨å…è®¸çš„åˆ—è¡¨ä¸­ ({', '.join(allowed_extensions_set) if allowed_extensions_set else 'æ— é™åˆ¶'})ã€‚",
            )

        for i, file_info in enumerate(file_infos_to_download):
            summary_stats["processed_from_filtered"] += 1
            current_file_num = i + 1
            uuid = file_info["uuid"]
            file_name = file_info["name"]
            expected_md5 = file_info["md5"]
            file_size_manifest = file_info["size"]

            s3_key = f"{uuid}/{file_name}"
            s3_uri = f"s3://{s3_bucket_name}/{s3_key}"

            target_data_uuid_dir = os.path.join(data_base_download_dir, uuid)
            local_file_path = os.path.join(target_data_uuid_dir, file_name)

            print(
                f"\n>>> æ­£åœ¨å¤„ç†æ–‡ä»¶ {current_file_num}/{summary_stats['total_filtered_for_download']}: {file_name} (UUID: {uuid})"
            )

            try:
                os.makedirs(target_data_uuid_dir, exist_ok=True)
            except OSError as e:
                message = f"åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥: {e}"
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log_entry(
                    "å¤±è´¥_å…¶ä»–",
                    uuid,
                    file_name,
                    s3_uri,
                    local_file_path,
                    expected_md5,
                    "N/A",
                    file_size_manifest,
                    message,
                )
                summary_stats["failed_other"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_å…¶ä»–",
                        "reason": message,
                    }
                )
                continue

            if args.skip_existing and os.path.exists(local_file_path):
                print(f"  ä¿¡æ¯: æ–‡ä»¶å·²å­˜åœ¨äº {local_file_path}ã€‚æ­£åœ¨è®¡ç®—æœ¬åœ° MD5...")
                local_md5, md5_error = calculate_md5(local_file_path)
                if md5_error:
                    message = f"è®¡ç®—æœ¬åœ°MD5å¤±è´¥: {md5_error}"
                    print(f"  é”™è¯¯: {message}", file=sys.stderr)
                    write_log_entry(
                        "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                        uuid,
                        file_name,
                        s3_uri,
                        local_file_path,
                        expected_md5,
                        "è®¡ç®—å‡ºé”™",
                        file_size_manifest,
                        message,
                    )
                    summary_stats["failed_md5_calc"] += 1
                    summary_stats["failed_files_details"].append(
                        {
                            "uuid": uuid,
                            "filename": file_name,
                            "status": "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                            "reason": message,
                        }
                    )
                elif local_md5 == expected_md5:
                    message = "æ–‡ä»¶å·²å­˜åœ¨ä¸”MD5åŒ¹é…ã€‚"
                    print(f"  æˆåŠŸ: {message} ({expected_md5})")
                    write_log_entry(
                        "å·²è·³è¿‡_MD5åŒ¹é…",
                        uuid,
                        file_name,
                        s3_uri,
                        local_file_path,
                        expected_md5,
                        local_md5,
                        file_size_manifest,
                        message,
                    )
                    summary_stats["skipped_md5_match"] += 1
                    continue
                else:
                    print(
                        f"  è­¦å‘Š: æ–‡ä»¶å·²å­˜åœ¨ä½†MD5ä¸åŒ¹é… (é¢„æœŸ: {expected_md5}, æœ¬åœ°: {local_md5})ã€‚å°†é‡æ–°ä¸‹è½½ã€‚"
                    )

            print(f"  ä¿¡æ¯: æ­£åœ¨ä» {s3_uri} ä¸‹è½½åˆ° {local_file_path}...")
            download_success = False
            last_exception_message = "æœªçŸ¥ä¸‹è½½é”™è¯¯"
            for attempt in range(args.retries + 1):
                try:
                    s3_client.download_file(s3_bucket_name, s3_key, local_file_path)
                    download_success = True
                    print(f"  ä¿¡æ¯: ä¸‹è½½å®Œæˆã€‚")
                    break
                except ClientError as e:
                    last_exception_message = (
                        f"AWS S3ä¸‹è½½é”™è¯¯ (å°è¯• {attempt + 1}/{args.retries + 1}): {e}"
                    )
                    print(f"  é”™è¯¯: {last_exception_message}", file=sys.stderr)
                    if attempt < args.retries:
                        print(f"  ä¿¡æ¯: {args.retry_delay}ç§’åé‡è¯•...")
                        time.sleep(args.retry_delay)
                    else:
                        write_log_entry(
                            "å¤±è´¥_AWSä¸‹è½½",
                            uuid,
                            file_name,
                            s3_uri,
                            local_file_path,
                            expected_md5,
                            "N/A",
                            file_size_manifest,
                            f"AWS S3ä¸‹è½½æœ€ç»ˆå¤±è´¥: {e}",
                        )
                        summary_stats["failed_aws_download"] += 1
                        summary_stats["failed_files_details"].append(
                            {
                                "uuid": uuid,
                                "filename": file_name,
                                "status": "å¤±è´¥_AWSä¸‹è½½",
                                "reason": str(e),
                            }
                        )
                except Exception as e:
                    last_exception_message = (
                        f"ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯ (å°è¯• {attempt + 1}): {e}"
                    )
                    print(f"  é”™è¯¯: {last_exception_message}", file=sys.stderr)
                    write_log_entry(
                        "å¤±è´¥_å…¶ä»–",
                        uuid,
                        file_name,
                        s3_uri,
                        local_file_path,
                        expected_md5,
                        "N/A",
                        file_size_manifest,
                        last_exception_message,
                    )
                    summary_stats["failed_other"] += 1
                    summary_stats["failed_files_details"].append(
                        {
                            "uuid": uuid,
                            "filename": file_name,
                            "status": "å¤±è´¥_å…¶ä»–",
                            "reason": str(e),
                        }
                    )
                    break

            if not download_success:
                continue

            print(f"  ä¿¡æ¯: æ­£åœ¨æ ¡éªŒä¸‹è½½æ–‡ä»¶çš„ MD5...")
            actual_md5_downloaded, md5_error_downloaded = calculate_md5(local_file_path)
            if md5_error_downloaded:
                message = f"è®¡ç®—ä¸‹è½½åæ–‡ä»¶MD5å¤±è´¥: {md5_error_downloaded}"
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log_entry(
                    "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                    uuid,
                    file_name,
                    s3_uri,
                    local_file_path,
                    expected_md5,
                    "è®¡ç®—å‡ºé”™",
                    file_size_manifest,
                    message,
                )
                summary_stats["failed_md5_calc"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_MD5è®¡ç®—é”™è¯¯",
                        "reason": message,
                    }
                )
            elif actual_md5_downloaded == expected_md5:
                message = "ä¸‹è½½æˆåŠŸä¸”MD5åŒ¹é…ã€‚"
                print(f"  æˆåŠŸ: {message} ({actual_md5_downloaded})")
                write_log_entry(
                    "æˆåŠŸ_MD5åŒ¹é…",
                    uuid,
                    file_name,
                    s3_uri,
                    local_file_path,
                    expected_md5,
                    actual_md5_downloaded,
                    file_size_manifest,
                    message,
                )
                summary_stats["successful_md5_match"] += 1
            else:
                message = f"æ–‡ä»¶å·²ä¸‹è½½ä½†MD5ä¸åŒ¹é… (é¢„æœŸ: {expected_md5}, å®é™…: {actual_md5_downloaded})"
                print(f"  é”™è¯¯: {message}", file=sys.stderr)
                write_log_entry(
                    "å¤±è´¥_MD5ä¸åŒ¹é…",
                    uuid,
                    file_name,
                    s3_uri,
                    local_file_path,
                    expected_md5,
                    actual_md5_downloaded,
                    file_size_manifest,
                    message,
                )
                summary_stats["failed_md5_mismatch"] += 1
                summary_stats["failed_files_details"].append(
                    {
                        "uuid": uuid,
                        "filename": file_name,
                        "status": "å¤±è´¥_MD5ä¸åŒ¹é…",
                        "reason": message,
                    }
                )

    print("\n\n==================================================")
    print("          ä¸‹è½½ä»»åŠ¡å®Œæˆæ‘˜è¦")
    print("==================================================")
    print(f" Manifest æ–‡ä»¶ä¸­å£°æ˜çš„æ€»æ–‡ä»¶æ•°: {summary_stats['total_manifest']}")
    print(
        f" æ ¹æ®æ‰©å±•åè¿‡æ»¤åè®¡åˆ’ä¸‹è½½çš„æ–‡ä»¶æ•°: {summary_stats['total_filtered_for_download']}"
    )
    print(
        f" â­ï¸ å› æ‰©å±•åä¸åŒ¹é…è€Œè·³è¿‡çš„æ–‡ä»¶æ•°: {summary_stats['skipped_extension_mismatch']}"
    )
    print(
        f" æœ¬æ¬¡è¿è¡Œå®é™…å°è¯•å¤„ç†çš„æ–‡ä»¶æ•° (æ¥è‡ªè¿‡æ»¤ååˆ—è¡¨): {summary_stats['processed_from_filtered']}"
    )
    print("--------------------------------------------------")
    print(f" âœ… æˆåŠŸä¸‹è½½å¹¶é€šè¿‡æ ¡éªŒçš„æ–‡ä»¶æ•°: {summary_stats['successful_md5_match']}")
    print(f" â­ï¸ å› å·²å­˜åœ¨ä¸”MD5åŒ¹é…è€Œè·³è¿‡çš„æ–‡ä»¶æ•°: {summary_stats['skipped_md5_match']}")
    print("--------------------------------------------------")
    total_failed = (
        summary_stats["failed_md5_mismatch"]
        + summary_stats["failed_aws_download"]
        + summary_stats["failed_md5_calc"]
        + summary_stats["failed_other"]
    )
    print(f" âŒ ä¸‹è½½å¤±è´¥æˆ–æ ¡éªŒæœªé€šè¿‡çš„æ–‡ä»¶æ€»æ•°: {total_failed}")
    if total_failed > 0:
        print(f"    - MD5 ä¸åŒ¹é…æ•°é‡: {summary_stats['failed_md5_mismatch']}")
        print(f"    - AWS ä¸‹è½½å¤±è´¥æ•°é‡: {summary_stats['failed_aws_download']}")
        print(f"    - æœ¬åœ°/ä¸‹è½½åMD5è®¡ç®—é”™è¯¯æ•°é‡: {summary_stats['failed_md5_calc']}")
        print(f"    - å…¶ä»–é”™è¯¯æ•°é‡: {summary_stats['failed_other']}")
    print("--------------------------------------------------")

    if summary_stats["failed_files_details"]:
        print("\nä»¥ä¸‹æ–‡ä»¶ä¸‹è½½å¤±è´¥æˆ–æ ¡éªŒæœªé€šè¿‡ (çŠ¶æ€ | UUID | æ–‡ä»¶å | åŸå› ):")
        sorted_failures = sorted(
            summary_stats["failed_files_details"], key=lambda x: x["status"]
        )
        for fail_info in sorted_failures:
            print(
                f"  - {fail_info['status']:<20} | {fail_info['uuid']:<37} | {fail_info['filename']:<50} | {fail_info['reason']}"
            )
        print("\nè¯·æ£€æŸ¥ä¸»æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(f"  {log_file_path}")
    elif (
        summary_stats["processed_from_filtered"] > 0
        and total_failed == 0
        and summary_stats["successful_md5_match"] + summary_stats["skipped_md5_match"]
        == summary_stats["processed_from_filtered"]
    ):
        print("ğŸ‰ æ‰€æœ‰å·²å¤„ç†çš„æ–‡ä»¶å‡å·²æˆåŠŸä¸‹è½½/è·³è¿‡å¹¶é€šè¿‡æ ¡éªŒã€‚")
    elif (
        summary_stats["processed_from_filtered"] == 0
        and summary_stats["total_filtered_for_download"] > 0
    ):
        print(
            "ğŸ¤” æœ¬æ¬¡è¿è¡Œæ²¡æœ‰å¤„ç†ä»»ä½•è¿‡æ»¤åçš„æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼Œå¯èƒ½æ‰€æœ‰æ–‡ä»¶åœ¨ä¸‹è½½å‰éƒ½é‡åˆ°äº†é—®é¢˜ï¼‰ã€‚"
        )
    elif (
        summary_stats["total_filtered_for_download"] == 0
        and summary_stats["total_manifest"] > 0
    ):
        print("â„¹ï¸ æ ¹æ®æ‰©å±•åè¿‡æ»¤åï¼Œæ²¡æœ‰æ–‡ä»¶ç¬¦åˆä¸‹è½½æ¡ä»¶ã€‚")
    elif summary_stats["total_manifest"] == 0:
        print("â„¹ï¸ Manifest æ–‡ä»¶ä¸ºç©ºæˆ–æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆæ¡ç›®ã€‚")

    print("==================================================")
    print(f"è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚è¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹: {log_file_path}")


if __name__ == "__main__":
    main()
